{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must be included at the beginning of each new notebook. Remember to change the app name.\n",
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('GuangzhouPM_Explore').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's read in the data. Note that it's in the format of csv.\n",
    "GuangzhouPM = spark.read.csv('i4_Dataset/GuangzhouPM20100101_20151231.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+-----+-----+-----+------+---------------+--------------------+----------+-----+-----+-----+-----+-----+-----+-------------+-----+\n",
      "|summary|   No| year|month|  day| hour|season|PM_City Station|PM_5th Middle School|PM_US Post| DEWP| HUMI| PRES| TEMP| cbwd|  Iws|precipitation|Iprec|\n",
      "+-------+-----+-----+-----+-----+-----+------+---------------+--------------------+----------+-----+-----+-----+-----+-----+-----+-------------+-----+\n",
      "|  count|52584|52584|52584|52584|52584| 52583|          32352|               21095|     32352|52583|52583|52583|52583|52583|52583|        52583|52583|\n",
      "+-------+-----+-----+-----+-----+-----+------+---------------+--------------------+----------+-----+-----+-----+-----+-----+-----+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "GuangzhouPM.describe().filter(col(\"summary\") == \"count\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GuangzhouPM_F = GuangzhouPM.filter(GuangzhouPM['year'] > 2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GuangzhouPM_RemoveNA = GuangzhouPM_F.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20074"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GuangzhouPM_RemoveNA.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "changedTypeGuangzhouPM_RemoveNA = GuangzhouPM_RemoveNA.withColumn(\"dayTime\", GuangzhouPM_RemoveNA[\"year\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- No: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- season: integer (nullable = true)\n",
      " |-- PM_City Station: integer (nullable = true)\n",
      " |-- PM_5th Middle School: integer (nullable = true)\n",
      " |-- PM_US Post: integer (nullable = true)\n",
      " |-- DEWP: double (nullable = true)\n",
      " |-- HUMI: integer (nullable = true)\n",
      " |-- PRES: double (nullable = true)\n",
      " |-- TEMP: double (nullable = true)\n",
      " |-- cbwd: string (nullable = true)\n",
      " |-- Iws: double (nullable = true)\n",
      " |-- precipitation: double (nullable = true)\n",
      " |-- Iprec: double (nullable = true)\n",
      " |-- dayTime: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "changedTypeGuangzhouPM_RemoveNA.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "GuangzhouPM2 = changedTypeGuangzhouPM_RemoveNA.withColumn('dayTime', \n",
    "\n",
    "                    F.concat(F.col('year'),F.lit('_'), F.col('month'),F.lit('_'),F.col('day'),F.lit('_'),F.col('hour')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "GuangzhouPM3 = GuangzhouPM2.withColumn('OutdoorSafeIndex', \n",
    "                                       F.when((F.col(\"PM_City Station\")<=26), 'Good')\\\n",
    "                                       .when((F.col('PM_City Station')> 40), 'Bad')\\\n",
    "                                       .otherwise ('Fair')\n",
    "                                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "GuangzhouPM4 = GuangzhouPM3.sort(\"year\",\"month\",\"day\",\"hour\",\"dayTime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "GuangzhouPM5 = GuangzhouPM4.drop(\"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "GuangzhouPM6 = GuangzhouPM5.drop('PM_5th Middle School','PM_US Post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "GuangzhouPM6_log = GuangzhouPM6.withColumn('PM_City Station_Log', F.log(GuangzhouPM6['PM_City Station']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import VectorAssembler and Vectors\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"season\", \"DEWP\", \n",
    "               \"HUMI\",'PRES','TEMP','Iws','precipitation','Iprec'],\n",
    "    outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = assembler.transform(GuangzhouPM6_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+\n",
      "|            features|PM_City Station|\n",
      "+--------------------+---------------+\n",
      "|[4.0,3.7,91.0,101...|             83|\n",
      "|[4.0,4.2,88.0,101...|             95|\n",
      "|[4.0,3.5,76.0,101...|             55|\n",
      "|[4.0,2.7,69.0,101...|             60|\n",
      "|[4.0,1.5,62.0,101...|             41|\n",
      "|[4.0,2.3,66.0,101...|             42|\n",
      "|[4.0,2.9,69.0,101...|             40|\n",
      "|[4.0,1.7,61.0,101...|             40|\n",
      "|[4.0,0.4,51.0,101...|             35|\n",
      "|[4.0,1.3,52.0,101...|             42|\n",
      "|[4.0,0.7,46.0,101...|             48|\n",
      "|[4.0,0.1,42.0,101...|             62|\n",
      "|[4.0,1.1,44.0,101...|             51|\n",
      "|[4.0,1.1,43.0,101...|             49|\n",
      "|[4.0,1.6,46.0,101...|             57|\n",
      "|[4.0,3.0,52.0,101...|             60|\n",
      "|[4.0,5.1,62.0,101...|             61|\n",
      "|[4.0,6.3,72.0,101...|             72|\n",
      "|[4.0,6.7,76.0,101...|             53|\n",
      "|[4.0,6.5,75.0,101...|             50|\n",
      "+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_GuangzhouPM = output.select(\"features\",'PM_City Station')\n",
    "final_GuangzhouPM.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+\n",
      "|            features|PM_City Station|\n",
      "+--------------------+---------------+\n",
      "|[4.0,0.4,51.0,101...|             35|\n",
      "|[4.0,0.7,46.0,101...|             48|\n",
      "|[4.0,1.1,44.0,101...|             51|\n",
      "|[4.0,1.6,70.0,101...|             29|\n",
      "|[4.0,1.7,61.0,101...|             40|\n",
      "|[4.0,1.7,69.0,101...|             39|\n",
      "|[4.0,1.8,72.0,101...|             26|\n",
      "|[4.0,1.8,73.0,101...|             30|\n",
      "|[4.0,2.1,74.0,101...|             31|\n",
      "|[4.0,2.3,66.0,101...|             42|\n",
      "|[4.0,2.3,69.0,101...|             37|\n",
      "|[4.0,2.4,75.0,101...|             33|\n",
      "|[4.0,2.5,68.0,101...|             43|\n",
      "|[4.0,2.5,70.0,101...|             37|\n",
      "|[4.0,2.7,68.0,101...|             33|\n",
      "|[4.0,2.7,68.0,101...|             48|\n",
      "|[4.0,2.7,69.0,101...|             60|\n",
      "|[4.0,2.7,70.0,101...|             26|\n",
      "|[4.0,2.8,70.0,101...|             38|\n",
      "|[4.0,2.9,67.0,101...|             47|\n",
      "+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_GuangzhouPM,test_GuangzhouPM = final_GuangzhouPM.randomSplit([0.7,0.3])\n",
    "train_GuangzhouPM.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20074"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_GuangzhouPM.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(labelCol='PM_City Station')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel = lr.fit(train_GuangzhouPM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [2.6213634242252555,-3.5771885011375284,0.8189846030581893,0.388534677881508,2.4386266821970897,-0.3400465489846502,-0.1571365426607032,-0.5963570064208119] Intercept: -402.2745868254232\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients: {} Intercept: {}\".format(lrModel.coefficients,lrModel.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = lrModel.evaluate(test_GuangzhouPM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|          residuals|\n",
      "+-------------------+\n",
      "| -4.141205213049091|\n",
      "|-14.185905247534947|\n",
      "| -24.59009659596535|\n",
      "|-24.098045006398365|\n",
      "|-5.1685839222430445|\n",
      "|-37.951890225581224|\n",
      "| -33.31947671776851|\n",
      "| -28.67964554094732|\n",
      "| -5.718337189385011|\n",
      "| -33.80857190155251|\n",
      "| -18.76679739122949|\n",
      "|-27.754327300454406|\n",
      "| -33.89669425966662|\n",
      "| -31.22663616786741|\n",
      "| -53.22172124787403|\n",
      "|-13.186276986346968|\n",
      "| -58.56327298958723|\n",
      "| 11.154553191083494|\n",
      "| -18.06865172423562|\n",
      "|  20.81855000029293|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "RSME: 31.699241821385712\n"
     ]
    }
   ],
   "source": [
    "test_results.residuals.show()\n",
    "print(\"RSME: {}\".format(test_results.rootMeanSquaredError))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.1352948625074547\n"
     ]
    }
   ],
   "source": [
    "print(\"R2: {}\".format(test_results.r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|   PM_City Station|\n",
      "+-------+------------------+\n",
      "|  count|             20074|\n",
      "|   mean|47.056241904951676|\n",
      "| stddev| 33.89550223308404|\n",
      "|    min|                 1|\n",
      "|    max|               526|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_GuangzhouPM.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import (VectorAssembler,VectorIndexer,\n",
    "                                OneHotEncoder,StringIndexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbwdIndex = StringIndexer(inputCol='cbwd',outputCol='cbwdIndex')\n",
    "\n",
    "# Now we can one hot encode these numbers. This converts the various outputs into a single vector.\n",
    "# This makes it easier to process when you have multiple classes.\n",
    "cbwdEncoder = OneHotEncoder(inputCol='cbwdIndex',outputCol='cbwdVec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression modelling\n",
    "assembler_L1 = VectorAssembler(inputCols=['cbwdVec', 'season','DEWP',\n",
    " 'HUMI',\n",
    " 'TEMP',\n",
    " 'PRES',\n",
    " 'precipitation', 'Iws'],outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_GuangzhouPM6 = LogisticRegression(featuresCol='features',labelCol='PM_City Station')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists everything we want to do. Index data, encode data, assemble data and then pass in the actual model.\n",
    "pipeline = Pipeline(stages=[cbwdIndex, cbwdEncoder,assembler_L1,log_reg_GuangzhouPM6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Guangzhou_L, test_Guangzhou_L = GuangzhouPM6_log.randomSplit([0.7,.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_model1 = pipeline.fit(train_Guangzhou_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_results1 = fit_model1.transform(test_Guangzhou_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "my_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction',\n",
    "                                       labelCol='PM_City Station')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC = my_eval.evaluate(L_results1)\n",
    "\n",
    "AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 6089\n",
      "Total Correct: 152\n"
     ]
    }
   ],
   "source": [
    "totalResults = L_results1.select('PM_City Station','prediction')\n",
    "\n",
    "correctResults = totalResults.filter(totalResults['PM_City Station'] == totalResults['prediction'])\n",
    "\n",
    "countTR = totalResults.count()\n",
    "print(\"Correct: \" + str(countTR))\n",
    "\n",
    "countTC = correctResults.count()\n",
    "print(\"Total Correct: \" + str(countTC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler_L2 = VectorAssembler(inputCols=['cbwdVec', 'season',\n",
    " 'HUMI',\n",
    " 'TEMP',\n",
    " 'precipitation', 'Iws'],outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg2 = LogisticRegression(featuresCol='features',labelCol='PM_City Station')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline2 = Pipeline(stages=[cbwdIndex, cbwdEncoder,assembler_L1,log_reg_GuangzhouPM6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_model2 = pipeline2.fit(train_Guangzhou_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_results2 = fit_model2.transform(test_Guangzhou_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_eval2 = BinaryClassificationEvaluator(rawPredictionCol='prediction',\n",
    "                                       labelCol='PM_City Station')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+\n",
      "|PM_City Station|prediction|\n",
      "+---------------+----------+\n",
      "|             60|      48.0|\n",
      "|             40|      57.0|\n",
      "|             35|      57.0|\n",
      "|             57|      57.0|\n",
      "|             60|      48.0|\n",
      "|             50|      48.0|\n",
      "|             55|      48.0|\n",
      "|             86|      48.0|\n",
      "|             82|      48.0|\n",
      "|             69|      48.0|\n",
      "|             59|      48.0|\n",
      "|             92|      48.0|\n",
      "|             53|      36.0|\n",
      "|             49|      36.0|\n",
      "|             43|      48.0|\n",
      "|             64|      39.0|\n",
      "|             58|      39.0|\n",
      "|             48|      39.0|\n",
      "|             45|      48.0|\n",
      "|             55|      48.0|\n",
      "+---------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "L_results2.select('PM_City Station','prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC2 = my_eval2.evaluate(L_results2)\n",
    "\n",
    "AUC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 6103\n",
      "Total Correct: 142\n"
     ]
    }
   ],
   "source": [
    "totalResults = L_results2.select('PM_City Station','prediction')\n",
    "\n",
    "correctResults = totalResults.filter(totalResults['PM_City Station'] == totalResults['prediction'])\n",
    "\n",
    "countTR = totalResults.count()\n",
    "print(\"Correct: \" + str(countTR))\n",
    "\n",
    "countTC = correctResults.count()\n",
    "print(\"Total Correct: \" + str(countTC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['year',\n",
       " 'month',\n",
       " 'day',\n",
       " 'hour',\n",
       " 'season',\n",
       " 'PM_City Station',\n",
       " 'DEWP',\n",
       " 'HUMI',\n",
       " 'PRES',\n",
       " 'TEMP',\n",
       " 'cbwd',\n",
       " 'Iws',\n",
       " 'precipitation',\n",
       " 'Iprec',\n",
       " 'dayTime',\n",
       " 'OutdoorSafeIndex',\n",
       " 'PM_City Station_Log']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random forest decision tree modeling \n",
    "GuangzhouPM6_log.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- season: integer (nullable = true)\n",
      " |-- PM_City Station: integer (nullable = true)\n",
      " |-- DEWP: double (nullable = true)\n",
      " |-- HUMI: integer (nullable = true)\n",
      " |-- PRES: double (nullable = true)\n",
      " |-- TEMP: double (nullable = true)\n",
      " |-- cbwd: string (nullable = true)\n",
      " |-- Iws: double (nullable = true)\n",
      " |-- precipitation: double (nullable = true)\n",
      " |-- Iprec: double (nullable = true)\n",
      " |-- dayTime: string (nullable = true)\n",
      " |-- OutdoorSafeIndex: string (nullable = false)\n",
      " |-- PM_City Station_Log: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GuangzhouPM6_log.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all features into one vector named features.\n",
    "assembler_DT1 = VectorAssembler(\n",
    "  inputCols=['season',\n",
    "             'PM_City Station',\n",
    "             'DEWP',\n",
    "             'HUMI',\n",
    "             'PRES',\n",
    "             'TEMP',\n",
    "             'Iws',\n",
    "             'precipitation',\n",
    "             'Iprec'],\n",
    "              outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_DT1 = assembler_DT1.transform(GuangzhouPM6_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+\n",
      "|            features|OutdoorSafeIndex|\n",
      "+--------------------+----------------+\n",
      "|[4.0,83.0,3.7,91....|             Bad|\n",
      "|[4.0,95.0,4.2,88....|             Bad|\n",
      "|[4.0,55.0,3.5,76....|             Bad|\n",
      "|[4.0,60.0,2.7,69....|             Bad|\n",
      "|[4.0,41.0,1.5,62....|             Bad|\n",
      "|[4.0,42.0,2.3,66....|             Bad|\n",
      "|[4.0,40.0,2.9,69....|            Fair|\n",
      "|[4.0,40.0,1.7,61....|            Fair|\n",
      "|[4.0,35.0,0.4,51....|            Fair|\n",
      "|[4.0,42.0,1.3,52....|             Bad|\n",
      "|[4.0,48.0,0.7,46....|             Bad|\n",
      "|[4.0,62.0,0.1,42....|             Bad|\n",
      "|[4.0,51.0,1.1,44....|             Bad|\n",
      "|[4.0,49.0,1.1,43....|             Bad|\n",
      "|[4.0,57.0,1.6,46....|             Bad|\n",
      "|[4.0,60.0,3.0,52....|             Bad|\n",
      "|[4.0,61.0,5.1,62....|             Bad|\n",
      "|[4.0,72.0,6.3,72....|             Bad|\n",
      "|[4.0,53.0,6.7,76....|             Bad|\n",
      "|[4.0,50.0,6.5,75....|             Bad|\n",
      "+--------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_dataDT1 = output_DT1.select(\"features\",'OutdoorSafeIndex')\n",
    "final_dataDT1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier,RandomForestClassifier\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"OutdoorSafeIndex\", outputCol=\"OutdoorSafeIndex output\")\n",
    "output_fixed = indexer.fit(output_DT1).transform(output_DT1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+--------------------+\n",
      "|OutdoorSafeIndex output|            features|\n",
      "+-----------------------+--------------------+\n",
      "|                    0.0|[4.0,83.0,3.7,91....|\n",
      "|                    0.0|[4.0,95.0,4.2,88....|\n",
      "|                    0.0|[4.0,55.0,3.5,76....|\n",
      "|                    0.0|[4.0,60.0,2.7,69....|\n",
      "|                    0.0|[4.0,41.0,1.5,62....|\n",
      "|                    0.0|[4.0,42.0,2.3,66....|\n",
      "|                    2.0|[4.0,40.0,2.9,69....|\n",
      "|                    2.0|[4.0,40.0,1.7,61....|\n",
      "|                    2.0|[4.0,35.0,0.4,51....|\n",
      "|                    0.0|[4.0,42.0,1.3,52....|\n",
      "|                    0.0|[4.0,48.0,0.7,46....|\n",
      "|                    0.0|[4.0,62.0,0.1,42....|\n",
      "|                    0.0|[4.0,51.0,1.1,44....|\n",
      "|                    0.0|[4.0,49.0,1.1,43....|\n",
      "|                    0.0|[4.0,57.0,1.6,46....|\n",
      "|                    0.0|[4.0,60.0,3.0,52....|\n",
      "|                    0.0|[4.0,61.0,5.1,62....|\n",
      "|                    0.0|[4.0,72.0,6.3,72....|\n",
      "|                    0.0|[4.0,53.0,6.7,76....|\n",
      "|                    0.0|[4.0,50.0,6.5,75....|\n",
      "+-----------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_dataDT1 = output_fixed.select('OutdoorSafeIndex output',\"features\")\n",
    "final_dataDT1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataDT1,test_dataDT1 = final_dataDT1.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- OutdoorSafeIndex output: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataDT1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(labelCol='OutdoorSafeIndex output',featuresCol='features')\n",
    "rfc = RandomForestClassifier(labelCol='OutdoorSafeIndex output',featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_model = dtc.fit(train_dataDT1)\n",
    "rfc_model = rfc.fit(train_dataDT1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare model accuracy \n",
    "prediction_dtc = dtc_model.transform(test_dataDT1)\n",
    "prediction_rfc = rfc_model.transform(test_dataDT1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+--------------------+----------------+-------------+----------+\n",
      "|OutdoorSafeIndex output|            features|   rawPrediction|  probability|prediction|\n",
      "+-----------------------+--------------------+----------------+-------------+----------+\n",
      "|                    0.0|[4.0,42.0,2.4,77....|[6572.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "|                    0.0|[4.0,42.0,2.5,77....|[6572.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "|                    0.0|[4.0,45.0,5.4,66....|[6572.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "|                    0.0|[4.0,46.0,4.6,68....|[6572.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "|                    0.0|[4.0,47.0,2.9,67....|[6572.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "|                    0.0|[4.0,48.0,2.7,68....|[6572.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "|                    0.0|[4.0,48.0,5.7,61....|[6572.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "|                    0.0|[4.0,49.0,1.1,43....|[6572.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "|                    0.0|[4.0,49.0,6.1,61....|[6572.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "|                    0.0|[4.0,51.0,1.1,44....|[6572.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "+-----------------------+--------------------+----------------+-------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction_dtc.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+--------------------+--------------------+--------------------+----------+\n",
      "|OutdoorSafeIndex output|            features|       rawPrediction|         probability|prediction|\n",
      "+-----------------------+--------------------+--------------------+--------------------+----------+\n",
      "|                    0.0|[4.0,42.0,2.4,77....|[19.0766281446299...|[0.95383140723149...|       0.0|\n",
      "|                    0.0|[4.0,42.0,2.5,77....|[19.0766281446299...|[0.95383140723149...|       0.0|\n",
      "|                    0.0|[4.0,45.0,5.4,66....|[19.0766281446299...|[0.95383140723149...|       0.0|\n",
      "|                    0.0|[4.0,46.0,4.6,68....|[19.0766281446299...|[0.95383140723149...|       0.0|\n",
      "|                    0.0|[4.0,47.0,2.9,67....|[19.0766281446299...|[0.95383140723149...|       0.0|\n",
      "|                    0.0|[4.0,48.0,2.7,68....|[19.0766281446299...|[0.95383140723149...|       0.0|\n",
      "|                    0.0|[4.0,48.0,5.7,61....|[19.4510583595203...|[0.97255291797601...|       0.0|\n",
      "|                    0.0|[4.0,49.0,1.1,43....|[19.4510583595203...|[0.97255291797601...|       0.0|\n",
      "|                    0.0|[4.0,49.0,6.1,61....|[19.4510583595203...|[0.97255291797601...|       0.0|\n",
      "|                    0.0|[4.0,51.0,1.1,44....|[19.4510583595203...|[0.97255291797601...|       0.0|\n",
      "+-----------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction_rfc.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_evaluator = MulticlassClassificationEvaluator(labelCol=\"OutdoorSafeIndex output\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_acc = acc_evaluator.evaluate(prediction_dtc)\n",
    "rfc_acc = acc_evaluator.evaluate(prediction_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the results!\n",
      "----------------------------------------\n",
      "A single decision tree has an accuracy of: 98.35%\n",
      "----------------------------------------\n",
      "A random forest ensemble has an accuracy of: 98.45%\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Here are the results!\")\n",
    "print('-'*40)\n",
    "print('A single decision tree has an accuracy of: {0:2.2f}%'.format(dtc_acc*100))\n",
    "print('-'*40)\n",
    "print('A random forest ensemble has an accuracy of: {0:2.2f}%'.format(rfc_acc*100))\n",
    "print('-'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler_DT2 = VectorAssembler(\n",
    "  inputCols=['season',\n",
    "             'PM_City Station',\n",
    "             'HUMI',\n",
    "             'Iws',\n",
    "             'precipitation'],\n",
    "              outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_DT2 = assembler_DT2.transform(GuangzhouPM6_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+\n",
      "|            features|OutdoorSafeIndex|\n",
      "+--------------------+----------------+\n",
      "|[4.0,83.0,91.0,1....|             Bad|\n",
      "|[4.0,95.0,88.0,3....|             Bad|\n",
      "|[4.0,55.0,76.0,5....|             Bad|\n",
      "|[4.0,60.0,69.0,8....|             Bad|\n",
      "|[4.0,41.0,62.0,9....|             Bad|\n",
      "|[4.0,42.0,66.0,11...|             Bad|\n",
      "|[4.0,40.0,69.0,2....|            Fair|\n",
      "|[4.0,40.0,61.0,4....|            Fair|\n",
      "|[4.0,35.0,51.0,6....|            Fair|\n",
      "|[4.0,42.0,52.0,1....|             Bad|\n",
      "|[4.0,48.0,46.0,4....|             Bad|\n",
      "|[4.0,62.0,42.0,1....|             Bad|\n",
      "|[4.0,51.0,44.0,3....|             Bad|\n",
      "|[4.0,49.0,43.0,5....|             Bad|\n",
      "|[4.0,57.0,46.0,7....|             Bad|\n",
      "|[4.0,60.0,52.0,8....|             Bad|\n",
      "|[4.0,61.0,62.0,0....|             Bad|\n",
      "|[4.0,72.0,72.0,1....|             Bad|\n",
      "|[4.0,53.0,76.0,1....|             Bad|\n",
      "|[4.0,50.0,75.0,1....|             Bad|\n",
      "+--------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_dataDT2 = output_DT2.select(\"features\",'OutdoorSafeIndex')\n",
    "final_dataDT2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer2 = StringIndexer(inputCol=\"OutdoorSafeIndex\", outputCol=\"OutdoorSafeIndex output\")\n",
    "output_fixed2 = indexer.fit(output_DT2).transform(output_DT2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+--------------------+\n",
      "|OutdoorSafeIndex output|            features|\n",
      "+-----------------------+--------------------+\n",
      "|                    0.0|[4.0,83.0,91.0,1....|\n",
      "|                    0.0|[4.0,95.0,88.0,3....|\n",
      "|                    0.0|[4.0,55.0,76.0,5....|\n",
      "|                    0.0|[4.0,60.0,69.0,8....|\n",
      "|                    0.0|[4.0,41.0,62.0,9....|\n",
      "|                    0.0|[4.0,42.0,66.0,11...|\n",
      "|                    2.0|[4.0,40.0,69.0,2....|\n",
      "|                    2.0|[4.0,40.0,61.0,4....|\n",
      "|                    2.0|[4.0,35.0,51.0,6....|\n",
      "|                    0.0|[4.0,42.0,52.0,1....|\n",
      "|                    0.0|[4.0,48.0,46.0,4....|\n",
      "|                    0.0|[4.0,62.0,42.0,1....|\n",
      "|                    0.0|[4.0,51.0,44.0,3....|\n",
      "|                    0.0|[4.0,49.0,43.0,5....|\n",
      "|                    0.0|[4.0,57.0,46.0,7....|\n",
      "|                    0.0|[4.0,60.0,52.0,8....|\n",
      "|                    0.0|[4.0,61.0,62.0,0....|\n",
      "|                    0.0|[4.0,72.0,72.0,1....|\n",
      "|                    0.0|[4.0,53.0,76.0,1....|\n",
      "|                    0.0|[4.0,50.0,75.0,1....|\n",
      "+-----------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_dataDT2 = output_fixed2.select('OutdoorSafeIndex output',\"features\")\n",
    "final_dataDT2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataDT2,test_dataDT2 = final_dataDT2.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc2 = DecisionTreeClassifier(labelCol='OutdoorSafeIndex output',featuresCol='features')\n",
    "rfc2 = RandomForestClassifier(labelCol='OutdoorSafeIndex output',featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc2_model = dtc.fit(train_dataDT2)\n",
    "rfc2_model = rfc.fit(train_dataDT2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dtc2 = dtc_model.transform(test_dataDT2)\n",
    "prediction_rfc2 = rfc_model.transform(test_dataDT2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc2_evaluator = MulticlassClassificationEvaluator(labelCol=\"OutdoorSafeIndex output\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc2_acc = acc2_evaluator.evaluate(prediction_dtc)\n",
    "rfc2_acc = acc2_evaluator.evaluate(prediction_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the results!\n",
      "----------------------------------------\n",
      "A single decision tree has an accuracy of: 98.49%\n",
      "----------------------------------------\n",
      "A random forest ensemble has an accuracy of: 98.30%\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Here are the results!\")\n",
    "print('-'*40)\n",
    "print('A single decision tree has an accuracy of: {0:2.2f}%'.format(dtc2_acc*100))\n",
    "print('-'*40)\n",
    "print('A random forest ensemble has an accuracy of: {0:2.2f}%'.format(rfc2_acc*100))\n",
    "print('-'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
